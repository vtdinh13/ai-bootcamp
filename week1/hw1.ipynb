{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4adf851f",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "For Q4-Q6 we'll reproduce what we did in the module, but with a different GitHub repo.\n",
    "\n",
    "We'll use the podcasts archive from DataTalks.Club: https://datatalks.club/podcast.html\n",
    "\n",
    "The data is available here: https://github.com/DataTalksClub/datatalksclub.github.io/tree/main/_podcast\n",
    "\n",
    "Download the data (only for podcasts). How many records are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43702b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "\n",
    "url = 'https://github.com/DataTalksClub/datatalksclub.github.io/tree/main/_podcast'\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "a_elements = driver.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "filenames=[]\n",
    "seen=set()\n",
    "for a in a_elements:\n",
    "    title = a.get_attribute('title')\n",
    "    # if href and href.endswith(('.md')):\n",
    "    if title.endswith(('.md')):\n",
    "        if title in seen:\n",
    "            continue\n",
    "        seen.add(title)\n",
    "        filenames.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645ffc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 185 records.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(filenames)} records.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for title in results:\n",
    "#     url = f'https://github.com/DataTalksClub/datatalksclub.github.io/blob/main/_podcast/{title}?plain=1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9fbc55",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "Let's prepare this data. It's already structured, so you can chunk it using paragraphs. Let's do chunk size 30 and overlap 15. How many chunks do you have in the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f71611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vancescadinh/miniconda3/envs/from-rag-to-agent/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 185/185 [00:25<00:00,  7.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import frontmatter\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "podcasts = []\n",
    "for f in tqdm(filenames):\n",
    "    url = f'https://raw.githubusercontent.com/DataTalksClub/datatalksclub.github.io/refs/heads/main/_podcast/{f}'\n",
    "\n",
    "    r = requests.get(url, timeout=30)\n",
    "    raw = r.text\n",
    "    content = re.sub(r'\\{\\{.*?\\}\\}', 'TEMPLATE_VAR', raw)\n",
    "    post = frontmatter.loads(content)\n",
    "    data = post.to_dict()\n",
    "    data['filename'] = f\n",
    "    podcasts.append(data)\n",
    "\n",
    "# flattened = []\n",
    "# for p in podcasts:\n",
    "#     attrs = p.get('attributes', {})\n",
    "#     record = {**attrs}\n",
    "#     record['transcript'] = p.get('transcript', '')\n",
    "#     record['filename'] = p.get('filename', '')\n",
    "#     flattened.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5610c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = []\n",
    "\n",
    "for p in podcasts:\n",
    "    transcript = p.get(\"transcript\", {})\n",
    "    chunks = transcript.get(\"chunk\", []) if isinstance(transcript, dict) else transcript\n",
    "    lines = [c[\"line\"] for c in chunks if isinstance(c, dict) and \"line\" in c]\n",
    "    merged_text = \" \".join(lines).strip()\n",
    "\n",
    "    flattened.append({\n",
    "        \"title\": p.get(\"title\"),\n",
    "        \"episode\": p.get(\"episode\"),\n",
    "        \"text\": merged_text\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f1e3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(seq, size, step):\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0, n, step):\n",
    "        chunk = seq[i:i+size]\n",
    "        result.append({'start': i, 'chunk': chunk})\n",
    "        if i + size >= n:\n",
    "            break\n",
    "\n",
    "    return result\n",
    "\n",
    "def chunk_documents(docs:list, size=30, step=15):\n",
    "    doc_chunks = []\n",
    "\n",
    "    for doc in docs:\n",
    "        doc_copy = doc.copy()\n",
    "        doc_content = doc_copy.pop('text')\n",
    "        chunks = sliding_window(doc_content, size, step)\n",
    "        for chunk in chunks:\n",
    "            chunk.update(doc_copy)\n",
    "        doc_chunks.extend(chunks)\n",
    "    return doc_chunks\n",
    "\n",
    "chunks = chunk_documents(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7955e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 516597 chunks.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(chunks)} chunks.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214e8320",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "Index the data with Index from minsearch. What's the first episode in the results for \"how do I make money with AI?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "615ec4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x17a0c2810>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import Index\n",
    "index = Index(\n",
    "    text_fields=['chunk', 'title']\n",
    ")\n",
    "\n",
    "index.fit(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "388aafb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make an Impact Through Volunteering Open Source Work is the first episode in the results.\n"
     ]
    }
   ],
   "source": [
    "query = 'how do I make money with AI?'\n",
    "\n",
    "print(f'{index.search(query)[0]['title']} is the first episode in the results.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "from-rag-to-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
